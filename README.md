# PEFT for Text Generation Stylization

Исследование методов Parameter-Efficient Fine-Tuning для стилизации генерации текста под разговорный стиль телеграм.

## Задача

Современные языковые модели генерируют текст в "корпоративном" стиле, далёком от живого общения в соцсетях. Цель — адаптировать LLM к разговорному стилю Telegram-комментариев, сравнив полное дообучение и PEFT-подходы.

## Данные

- Собственный датасет из Telegram: посты + комментарии к ним
- Препроцессинг: очистка от ссылок, замена эмодзи на текст, фильтрация по длине
- Разбиение: train / val / test

## Эксперименты

| Подход | Модель | Статус |
|--------|--------|--------|
| Full fine-tuning | ruGPT-3 Small (sberbank-ai) | Обучена, 4 эпохи |
| LoRA | Qwen2.5-0.5B (r=8, α=16) | Обучена, несколько этапов (всего 8 эпох) |
| (IA)³ | Qwen2.5-0.5B (r=8, α=16) | В процессе |

### Наблюдения

- **Full fine-tuning**: лосс расходится с первой эпохи, но качество генерации субъективно улучшается к 4–6 эпохе (ответы становятся конкретнее и привязаны к посту)
- **LoRA**: после первых эпох модель отвечает "слишком общо", с увеличением числа эпох ответы становятся ближе по смыслу к постам, но ещё не полностью ухватывают контекст

## Evaluation

- BERTScore для оценки семантической близости генерации к реальным комментариям
- Планируется: LLM-as-a-judge для оценки стилистической 
- Планируется: ROUGE перекрытия с постом

## Структура

```
├── EDA_and_preprocess.ipynb    # Анализ данных, очистка текста
├── train_val_test_split.ipynb  # Разбиение на выборки
├── Fine_tuned_model.ipynb      # Full fine-tuning ruGPT-3 Small
├── LoRA.ipynb                  # LoRA дообучение Qwen2.5-0.5B
├── Test_bert_score.ipynb       # Оценка через BERTScore
└── README.md
```

## Стек

Python, PyTorch, HuggingFace Transformers, PEFT (LoRA), Datasets, BERTScore, Sentence-Transformers

## Статус

В процессе — диплом, защита 2026