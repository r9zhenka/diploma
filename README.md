# diploma
My diploma is devoted to the problem of the unnatural "corporate" style communication of modern language models. 
Тема: 
Адаптация языковых моделей/LLM для симуляции пользовательского поведения в онлайн-дискуссиях ИЛИ
Методы fine-tuning (или сместить внимание на peft) языковых моделей для трансфера стиля в (текстовых) диалогах
# Структура веток
## main branch
  Еще не делал, но нужно
  - собрать датасет на 50-100к + собирать не 3 комментария, а 7-10.
  - модель yandexgpt5 занимает примерно 16гб оперативки и полностью файн-тюнить ее не получится в бесплатном коллабе => нужно использовать peft методы. При этом даже при них нужно будет 16гб оперативки для forward and backward проходок => нужно будет квантизовать. Самый очевидный вариант QLora. Сравнить дообучение инстракт версии и претрейн. Если не получится уместиться в коллаб, то надо поискать модель поменьше, например, от vikhr.
  - Помимо прочего, интересный анализ на предмет сгенерированного текста предложен в [этой статье](https://arxiv.org/html/2410.16107v1#bib.bib4). Можно попробовать адаптировать под русский язык и взять часть  Biber's-features, оценивать и ими генерацию модели. Но учитывая, что комментарии обычно до 50 слов, то нельзя быть уверенным в легкости этой адаптации.

    
## light_version
Собрал датасет с телеграма на 5002 постов, к каждому по 3 комментария (некоторые комментарии пустые или содержат один смайл, поэтому остаются иногда 1-2 комментария к посту). 
Взял ruSBERgpt3-small с [125М параметров](https://arxiv.org/pdf/2309.10931)
Провел полный файн-тюнинг в 10 эпох на разбитом на train-val датасете.
Метрики: для оценки нужно учитывать схожесть стилей речи и корректность. 
Под корректностью понимается связь текста с постом, улавливание общей реакции. Т.е. семантическая связь с комментариями => максимум из оценки bert_score с другими комментариями покажет, что сгенерированная мысль была написана и человеком. Проблема: на данный момент bert_score оценивает семантику по словам. Тогда предложение по типу "я каждый день делаю зубные щетки" и "я каждый день использую зубную щетку" будут очень близки. Но если первый комментарий будет написан под постом про здоровье зубов, то несмотря на семантическую близость, критерий уместности/адекватности он не пройдет. Возможное решение: 1. модель может допускать такое из-за того, что плохо обучена изначально, либо из-за полного файн-тюнинга происходит [catastrophic forgetting](https://arxiv.org/html/2403.05175v1). Тогда использование большей модели и методов peft решит это. Либо, если проблема связана с метрикой, можно попробовать оценивать семантическую близость n-грамм. Тогда "делать зубные щетки" и "использовать зуюные щетки" могут различаться сильнее.
Схожесть стиля можно учитывать через перплексию. Для этого можно обучить отдельную легкую модель на открытых датасетах твиттера, либо на частях [корпуса русского языка](https://ruscorpora.ru/). Она должна будет оценивать вероятность сгенерированной последовательности, после чего нужно будет сравнить перплексию с остальными комментариями


